{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-01O8l0PpFda"
   },
   "outputs": [],
   "source": [
    "!rm -r /content/logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vk3l16BYpCxM"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyBNEGchpEJ8"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ygJAp-8o0ak"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# download and load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_validation, y_validation) = mnist.load_data()\n",
    "\n",
    "# transform images to vectors (flatenning) and change type\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_validation = x_validation.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_validation = x_validation.astype('float32')\n",
    "\n",
    "# normalize vectors values from [0,255] -> [0,1]\n",
    "x_train /= 255\n",
    "x_validation /= 255\n",
    "\n",
    "print('train samples', x_train.shape)\n",
    "print('test samples', x_validation.shape)\n",
    "\n",
    "print('train label samples', y_train.shape)\n",
    "print('test label samples', y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8yd6Jgzo320"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# convert labels from category to one-hot\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_validation = to_categorical(y_validation, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GL3MVhUpIE0"
   },
   "outputs": [],
   "source": [
    "N_EPOCH = 100\n",
    "\n",
    "# define each model training configuration\n",
    "experiments = [\n",
    "\n",
    "    # base\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.SGD, 'lr': 0.1, 'layers': [128, 64, 32], 'activation': 'relu',\n",
    "     'batch_size': 16, 'dropout': 0.5, 'BN': True},\n",
    "\n",
    "    # no dropout\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.SGD, 'lr': 0.1, 'layers': [128, 64, 32], 'activation': 'relu',\n",
    "     'batch_size': 16, 'dropout': 0.0, 'BN': True},\n",
    "\n",
    "    # deeper network\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.SGD, 'lr': 0.1, 'layers': [128, 64, 32, 16], 'activation': 'relu',\n",
    "     'batch_size': 16, 'dropout': 0.5, 'BN': True},\n",
    "\n",
    "    # batch size of 32\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.SGD, 'lr': 0.1, 'layers': [128, 64, 32], 'activation': 'relu',\n",
    "     'batch_size': 32, 'dropout': 0.5, 'BN': True},\n",
    "\n",
    "    # batch size of 64\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.SGD, 'lr': 0.1, 'layers': [128, 64, 32], 'activation': 'relu',\n",
    "     'batch_size': 64, 'dropout': 0.5, 'BN': True},\n",
    "\n",
    "    # activation function sigmoid\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.SGD, 'lr': 0.1, 'layers': [128, 64, 32], 'activation': 'sigmoid',\n",
    "     'batch_size': 16, 'dropout': 0.5, 'BN': True},\n",
    "\n",
    "    # no batch normalization\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.SGD, 'lr': 0.1, 'layers': [128, 64, 32], 'activation': 'relu',\n",
    "     'batch_size': 16, 'dropout': 0.5, 'BN': False},\n",
    "\n",
    "    # smaller learning rate\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.SGD, 'lr': 0.01, 'layers': [128, 64, 32], 'activation': 'relu',\n",
    "     'batch_size': 16, 'dropout': 0.5, 'BN': True},\n",
    "\n",
    "    # optimizer Adam\n",
    "    {'epoch': N_EPOCH, 'optimizer': tf.keras.optimizers.Adam, 'lr': 0.1, 'layers': [128, 64, 32], 'activation': 'relu',\n",
    "     'batch_size': 16, 'dropout': 0.5, 'BN': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLSBY5KsubMB"
   },
   "outputs": [],
   "source": [
    "MODELS = {}\n",
    "for i, config in enumerate(experiments):\n",
    "\n",
    "    # specify tensorboard directory\n",
    "    logdir = \"logs/scalars/\" + str(i)\n",
    "\n",
    "    # create tensorboard callback\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "    # create saving model callback\n",
    "    checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='model_{}.ckpt'.format(str(i)), monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "    # define model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(config['layers'][0], activation=config['activation'], input_dim=784))\n",
    "    for hiddden_dim in config['layers'][1:]:\n",
    "        if config['BN']:\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(config['dropout']))\n",
    "        model.add(tf.keras.layers.Dense(hiddden_dim, activation=config['activation']))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    # define optimizer\n",
    "    optim = config['optimizer'](lr=config['lr'])\n",
    "\n",
    "    # compile model with optimizer, loss and metrics\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    history = model.fit(x_train, y_train, validation_split=0.2, batch_size=config['batch_size'], epochs=config['epoch'], verbose=1, callbacks=[tensorboard_callback, checkpointer])\n",
    "\n",
    "    # add model to dictionary of models\n",
    "    MODELS.update({'experiment_{}'.format(str(i)): (history, model)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOnjLx1p6Yxt"
   },
   "outputs": [],
   "source": [
    "# select model with best validation loss\n",
    "# the name should be set according to the validation accuracy\n",
    "history, model = MODELS['experiment_0']   # change name of model based on best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovyZKeYi6Y0X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# display best model prediction on validation examples\n",
    "for _ in range(10):\n",
    "\n",
    "    # display example\n",
    "    idx = random.choice(range(x_validation.shape[0]))\n",
    "    image = x_validation[idx].reshape(28, 28)\n",
    "    image = (image * 255).astype(dtype=np.uint8)\n",
    "    display(Image.fromarray(image).resize((128,128)))\n",
    "\n",
    "    # display model prediction\n",
    "    datapoint = x_validation[idx].reshape(1, 784)\n",
    "    predict_prob = model.predict(datapoint, verbose=0)\n",
    "    print('i am confident around {:.2f}% that this image corresponds to digit {}'.format(np.amax(predict_prob)*100, np.argmax(predict_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnUh0DwbD_gt"
   },
   "outputs": [],
   "source": [
    "x_validation = x_validation.reshape(10000, 784)\n",
    "loss, acc = model.evaluate(x_validation, y_validation, batch_size=64, verbose=1)\n",
    "print('test accuracy: ', round(100*acc, 2))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
